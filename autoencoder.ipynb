{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import PIL\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "INPUT_CHANNELS = 1\n",
    "import cv2\n",
    "def path2img(path):\n",
    "    img = PIL.Image.open(path)\n",
    "    img = img.resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "    return img\n",
    "def path2imgarray(path, binary=True):\n",
    "\n",
    "    img = PIL.Image.open(path)\n",
    "    img = img.resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "    img = np.array(img)\n",
    "    \n",
    "    def binaryzation(img):\n",
    "        cv_img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "        return cv_img\n",
    "    img = binaryzation(img) if binary else img\n",
    "    img = img / 255.0\n",
    "    img = img.reshape(IMG_HEIGHT, IMG_WIDTH, (1 if binary else 3) )\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(keras.Model):\n",
    "    def __init__(self):\n",
    "        layers = keras.layers\n",
    "        super().__init__()\n",
    "        \n",
    "            \n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, INPUT_CHANNELS)),\n",
    "            layers.Conv2D(16, (3, 3), activation='relu', padding='same', strides=2),# \n",
    "            layers.Conv2D(8, (3, 3), activation='relu', padding='same', strides=2), # \n",
    "        ])\n",
    "\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'), # \n",
    "            layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'), # \n",
    "            layers.Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same') # \n",
    "        ])\n",
    "        \n",
    "            \n",
    "    def call(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the model\n",
    "autoencoder = AutoEncoder()\n",
    "\n",
    "trainLoss = tf.keras.metrics.Mean(name='trainLoss')\n",
    "valLoss = tf.keras.metrics.Mean(name='valLoss')\n",
    "calLoss = tf.keras.losses.MeanSquaredError()\n",
    "l1 = tf.keras.regularizers.L1(l1=0.01)\n",
    "\n",
    "autoencoder.build(input_shape=(None, IMG_HEIGHT, IMG_WIDTH, INPUT_CHANNELS))\n",
    "autoencoder.summary()\n",
    "# 查看每一层\n",
    "for layer in autoencoder.encoder.layers:\n",
    "    print(layer.name, layer.output_shape)\n",
    "for layer in autoencoder.decoder.layers:\n",
    "    print(layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainStap(model):\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    @tf.function\n",
    "    def trainStep(images, labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model.encode(images)\n",
    "            predictions = model.decode(predictions)\n",
    "\n",
    "            loss = calLoss(labels, predictions) # * l1\n",
    "        # print(loss)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        trainLoss(loss)\n",
    "    return trainStep\n",
    "def getValStep(model):\n",
    "    @tf.function\n",
    "    def valStep(images, labels):\n",
    "        predictions = model(images, training=False)\n",
    "        loss = calLoss(labels, predictions)\n",
    "\n",
    "        valLoss(loss)\n",
    "    return valStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "trainNoiseDir = './dataset/train/noise/'\n",
    "trainNoNoiseDir = './dataset/train/noNoise/'\n",
    "testNoiseDir = './dataset/test/noise/'\n",
    "testNoNoiseDir = './dataset/test/noNoise/'\n",
    "# noise 和 noNoise 是输入和标签\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ([path2imgarray(path, binary=False) for path in tf.io.gfile.glob(trainNoiseDir + '*.jpg')], \n",
    "    [path2imgarray(path, binary=True) for path in tf.io.gfile.glob(trainNoNoiseDir + '*.jpg')])\n",
    ")\n",
    "dataset = dataset.shuffle(buffer_size=1000)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "valDataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ([path2imgarray(path, binary=False) for path in tf.io.gfile.glob(testNoiseDir + '*.jpg')],\n",
    "    [path2imgarray(path, binary=True) for path in tf.io.gfile.glob(testNoNoiseDir + '*.jpg')])\n",
    ")\n",
    "\n",
    "valDataset = valDataset.shuffle(buffer_size=1000)\n",
    "valDataset = valDataset.batch(BATCH_SIZE)\n",
    "valDataset = valDataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "print(len(dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time,random\n",
    "# train face1\n",
    "trainStep = getTrainStap(autoencoder)\n",
    "valiStep = getValStep(autoencoder)\n",
    "EPOCHS = 2000\n",
    "\n",
    "lossHistory = []\n",
    "epochsRange = []\n",
    "\n",
    "valLossHistory = []\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    trainLoss.reset_states()\n",
    "    valLoss.reset_states()\n",
    "        \n",
    "    for images, labels in dataset:\n",
    "        trainStep(images, labels)\n",
    "    \n",
    "    # random validate\n",
    "    for images, labels in valDataset.take(10):\n",
    "        valiStep(images,labels)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    print(\n",
    "        f'\\nEpoch {epoch + 1}, '\n",
    "        f'\\nTrain      Loss: {trainLoss.result()}, '\n",
    "        f'\\nValidation Loss: {valLoss.result()}'\n",
    "        f' - {int((time.time() - start) / (epoch + 1) * (EPOCHS - epoch)) / 60} minutes left, '\n",
    "    )\n",
    "    lossHistory.append(trainLoss.result())\n",
    "    valLossHistory.append(valLoss.result())\n",
    "    epochsRange.append(epoch)\n",
    "\n",
    "plt.plot(epochsRange[100:], lossHistory[100:], label='Trainning Loss')\n",
    "plt.plot(epochsRange[100:], valLossHistory[100:], label='Validation Loss')\n",
    "# 图例\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minloss = np.min(valLossHistory)\n",
    "epochln = len(epochsRange)\n",
    "for i in range(10):\n",
    "  plt.figure(figsize=(5, 5), dpi=200)\n",
    "  plt.plot([0, epochln], [minloss,minloss],linestyle='--',color='black')\n",
    "  # text minloss\n",
    "  plt.text(0, minloss, '%.5f'%minloss, fontsize=10)\n",
    "  plt.plot(epochsRange[10 * i:], lossHistory[10 * i:], label='Training Loss')\n",
    "  plt.plot(epochsRange[10 * i:], valLossHistory[10 * i:], label='Validation Loss')\n",
    "  # 图例\n",
    "  plt.legend(loc='upper right')\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save_weights('./captchModel.h5')\n",
    "#autoencoder.load_weights('./captchModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(ncols=6,nrows=2)\n",
    "fig.dpi = 200\n",
    "trainData = [*dataset.take(1)][0]\n",
    "valData = [*valDataset.take(1)][0]\n",
    "trainInputImg = trainData[0][:1]\n",
    "trainTargetImg = trainData[1][:1]\n",
    "valInputImg = valData[0][:1] \n",
    "valTargetImg = valData[1][:1]\n",
    "ax[0][0].imshow(trainInputImg[0])\n",
    "ax[0][1].imshow(trainTargetImg[0])\n",
    "ax[0][2].imshow(autoencoder(trainInputImg,training=False)[0])\n",
    "ax[1][0].imshow(valInputImg[0])\n",
    "ax[1][1].imshow(valTargetImg[0])\n",
    "ax[1][2].imshow(autoencoder(valInputImg,training=False)[0])\n",
    "import cv2\n",
    "# 二值化\n",
    "def binaryzation(img):\n",
    "    cv_img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    cv_img = cv2.threshold(cv_img,190,255,cv2.THRESH_BINARY_INV)[1]\n",
    "    return cv_img\n",
    "# read img from np float\n",
    "# float to int\n",
    "def img2int(img):\n",
    "    img *= 255\n",
    "    img = img.astype(np.uint8)\n",
    "    return img\n",
    "ax[0][3].imshow(np.array(autoencoder(trainInputImg,training=False)[0]))\n",
    "ax[1][3].imshow(np.array(autoencoder(valInputImg,training=False)[0]))\n",
    "# 中值滤波\n",
    "def medianBlur(img):\n",
    "    img = cv2.medianBlur(img,5)\n",
    "    return img\n",
    "ax[0][4].imshow(medianBlur(np.array(autoencoder(trainInputImg,training=False)[0])))\n",
    "ax[1][4].imshow(medianBlur(np.array(autoencoder(valInputImg,training=False)[0])))\n",
    "ax[0][5].imshow(medianBlur(img2int(np.array(trainInputImg[0]))))\n",
    "ax[1][5].imshow(medianBlur(img2int(np.array(valInputImg[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_100Model = AutoEncoder()\n",
    "_400Model = AutoEncoder()\n",
    "_100Model.build(input_shape=(None,IMG_HEIGHT,IMG_WIDTH,1))\n",
    "_400Model.build(input_shape=(None,IMG_HEIGHT,IMG_WIDTH,1))\n",
    "_100Model.load_weights('./100dataset2000epoch.h5')\n",
    "_400Model.load_weights('./400dataset2000epoch.h5')\n",
    "trainSet = [*zip(\n",
    "  [path2imgarray(path, binary=False) for path in tf.io.gfile.glob(testNoiseDir + '*.jpg')],\n",
    "  [path2imgarray(path, binary=True) for path in tf.io.gfile.glob(testNoiseDir + '*.jpg')]\n",
    ")]\n",
    "random.shuffle(trainSet)\n",
    "trainSet = trainSet[:5]\n",
    "fig, ax =plt.subplots(ncols=5,nrows=2,figsize=(13, 4), dpi=200)\n",
    "idx = 0\n",
    "for origin, binary in trainSet:\n",
    "  # 去除刻度\n",
    "    ax[0][idx].xaxis.set_visible(False)\n",
    "    ax[0][idx].yaxis.set_visible(False)\n",
    "    \n",
    "    ax[0][idx].imshow(origin)\n",
    "    ax[1][idx].imshow(_100Model(binary.reshape(1,IMG_HEIGHT, IMG_WIDTH,1),training=False)[0])\n",
    "    idx += 1\n",
    "fig, ax =plt.subplots(ncols=5,nrows=2,figsize=(13, 4), dpi=200)\n",
    "idx = 0\n",
    "for origin, binary in trainSet:\n",
    "  # 去除刻度\n",
    "    ax[0][idx].xaxis.set_visible(False)\n",
    "    ax[0][idx].yaxis.set_visible(False)\n",
    "    ax[0][idx].imshow(origin)\n",
    "    ax[1][idx].imshow(_400Model(binary.reshape(1,IMG_HEIGHT, IMG_WIDTH,1),training=False)[0])\n",
    "    idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = AutoEncoder()\n",
    "autoencoder.build(input_shape=(None,IMG_HEIGHT,IMG_WIDTH,1))\n",
    "autoencoder.load_weights('./100dataset2000epoch.h5')\n",
    "img = path2imgarray('./noise-BNEZ.jpg', binary=False)\n",
    "binary = path2imgarray('./noise-BNEZ.jpg', binary=True)\n",
    "img = img.reshape((1,IMG_HEIGHT,IMG_WIDTH,3))\n",
    "binary = binary.reshape((1,IMG_HEIGHT,IMG_WIDTH,1)) \n",
    "fig,ax = plt.subplots(ncols=2,nrows=1)\n",
    "fig.dpi = 100\n",
    "ax[0].imshow(img[0])\n",
    "ax[1].imshow(\n",
    "    autoencoder(binary,training=False)[0]\n",
    ")\n",
    "# conv2d (None, 64, 64, 16)\n",
    "# conv2d_1 (None, 32, 32, 8)\n",
    "# conv2d_transpose (None, 64, 64, 8)\n",
    "# conv2d_transpose_1 (None, 128, 128, 16)\n",
    "# conv2d_2 (None, 128, 128, 1)\n",
    "_6416out = autoencoder.encoder.layers[0](binary)\n",
    "_328out = autoencoder.encoder.layers[1](_6416out)\n",
    "_648out = autoencoder.decoder.layers[0](_328out)\n",
    "_12816out = autoencoder.decoder.layers[1](_648out)\n",
    "out = autoencoder.decoder.layers[2](_12816out)\n",
    "fig, ax = plt.subplots(ncols=4,nrows=4,dpi =200)\n",
    "# title\n",
    "ax[0][0].set_title('encoder layer1 (None, 64, 64, 16)', fontsize=8,)\n",
    "for i in range(16):\n",
    "    ax[i//4][i%4].imshow(_6416out[0][:,:,i])\n",
    "    ax[i//4][i%4].xaxis.set_visible(False)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(ncols=4,nrows=2,dpi =200)\n",
    "# title\n",
    "ax[0][0].set_title('encoder layer2 (None, 32, 32, 8)', fontsize=8,)\n",
    "for i in range(8):\n",
    "    ax[i//4][i%4].imshow(_328out[0][:,:,i])\n",
    "    ax[i//4][i%4].xaxis.set_visible(False)\n",
    "\n",
    "plt.show()\n",
    "# title\n",
    "fig, ax = plt.subplots(ncols=4,nrows=2,dpi =200)\n",
    "ax[0][0].set_title('decoder layer1 (None, 64, 64, 8)', fontsize=8,)\n",
    "for i in range(8):\n",
    "    ax[i//4][i%4].imshow(_648out[0][:,:,i])\n",
    "    ax[i//4][i%4].xaxis.set_visible(False)\n",
    "plt.show()\n",
    "fig,ax = plt.subplots(ncols=4,nrows=4,dpi =200)\n",
    "# title\n",
    "ax[0][0].set_title('decoder layer2 (None, 128, 128, 16)', fontsize=8,)\n",
    "for i in range(16):\n",
    "    ax[i//4][i%4].imshow(_12816out[0][:,:,i])\n",
    "    ax[i//4][i%4].xaxis.set_visible(False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2536a8b7348cda3df24488cb4703f2095d9cd957069c8076928c7127913566d2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
